{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91f68b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "--- Applying Feature Cleaning ---\n",
      "Dropped: ['age', 'internet_access']\n",
      "\n",
      "One-Hot Encoding...\n",
      "Final Input Dimension: 27\n",
      "\n",
      "Starting XGBoost CV Training (No Stacking)...\n",
      "[0]\tvalidation_0-rmse:18.59631\n",
      "[500]\tvalidation_0-rmse:8.78324\n",
      "[1000]\tvalidation_0-rmse:8.75860\n",
      "[1500]\tvalidation_0-rmse:8.74625\n",
      "[2000]\tvalidation_0-rmse:8.73984\n",
      "[2500]\tvalidation_0-rmse:8.73657\n",
      "[3000]\tvalidation_0-rmse:8.73489\n",
      "[3500]\tvalidation_0-rmse:8.73423\n",
      "[3746]\tvalidation_0-rmse:8.73446\n",
      "[Fold 1] best_iter=3547  RMSE=8.734093\n",
      "[0]\tvalidation_0-rmse:18.64005\n",
      "[500]\tvalidation_0-rmse:8.79616\n",
      "[1000]\tvalidation_0-rmse:8.77037\n",
      "[1500]\tvalidation_0-rmse:8.75793\n",
      "[2000]\tvalidation_0-rmse:8.75066\n",
      "[2500]\tvalidation_0-rmse:8.74707\n",
      "[3000]\tvalidation_0-rmse:8.74523\n",
      "[3500]\tvalidation_0-rmse:8.74425\n",
      "[4000]\tvalidation_0-rmse:8.74364\n",
      "[4196]\tvalidation_0-rmse:8.74372\n",
      "[Fold 2] best_iter=3997  RMSE=8.743622\n",
      "[0]\tvalidation_0-rmse:18.81782\n",
      "[500]\tvalidation_0-rmse:8.78591\n",
      "[1000]\tvalidation_0-rmse:8.75992\n",
      "[1500]\tvalidation_0-rmse:8.74746\n",
      "[2000]\tvalidation_0-rmse:8.74082\n",
      "[2500]\tvalidation_0-rmse:8.73774\n",
      "[3000]\tvalidation_0-rmse:8.73631\n",
      "[3500]\tvalidation_0-rmse:8.73607\n",
      "[3923]\tvalidation_0-rmse:8.73605\n",
      "[Fold 3] best_iter=3724  RMSE=8.735779\n",
      "[0]\tvalidation_0-rmse:18.72191\n",
      "[500]\tvalidation_0-rmse:8.80172\n",
      "[1000]\tvalidation_0-rmse:8.77737\n",
      "[1500]\tvalidation_0-rmse:8.76502\n",
      "[2000]\tvalidation_0-rmse:8.75879\n",
      "[2500]\tvalidation_0-rmse:8.75557\n",
      "[3000]\tvalidation_0-rmse:8.75377\n",
      "[3500]\tvalidation_0-rmse:8.75305\n",
      "[3672]\tvalidation_0-rmse:8.75301\n",
      "[Fold 4] best_iter=3473  RMSE=8.752906\n",
      "[0]\tvalidation_0-rmse:18.68262\n",
      "[500]\tvalidation_0-rmse:8.81622\n",
      "[1000]\tvalidation_0-rmse:8.79112\n",
      "[1500]\tvalidation_0-rmse:8.78002\n",
      "[2000]\tvalidation_0-rmse:8.77391\n",
      "[2500]\tvalidation_0-rmse:8.77036\n",
      "[3000]\tvalidation_0-rmse:8.76905\n",
      "[3500]\tvalidation_0-rmse:8.76835\n",
      "[3908]\tvalidation_0-rmse:8.76831\n",
      "[Fold 5] best_iter=3709  RMSE=8.767982\n",
      "\n",
      "OOF RMSE (Direct XGBoost): 8.746885\n",
      "Retraining on full dataset with 3690 estimators...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# XGBoost + User Feature Cleaning (Direct Model)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "# Set GPU device (change to \"-1\" if you don't have a GPU)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Configuration\n",
    "# -----------------------------\n",
    "DATA_DIR = \"/rds/rds-lxu/ml_datasets/exam_score_predict\"\n",
    "TRAIN_PATH = f\"{DATA_DIR}/train.csv\"\n",
    "TEST_PATH  = f\"{DATA_DIR}/test.csv\"\n",
    "\n",
    "ID_COL = \"id\"\n",
    "TARGET = \"exam_score\"\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load Data\n",
    "# -----------------------------\n",
    "print(\"Loading data...\")\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "y = train_df[TARGET].astype(float).values\n",
    "train_ids = train_df[ID_COL].values\n",
    "test_ids  = test_df[ID_COL].values\n",
    "\n",
    "train_X0 = train_df.drop(columns=[TARGET, ID_COL]).copy()\n",
    "test_X0  = test_df.drop(columns=[ID_COL]).copy()\n",
    "\n",
    "# -----------------------------\n",
    "# 2) APPLY USER FEATURE CLEANING\n",
    "# -----------------------------\n",
    "cols_to_drop = [\"age\", \"internet_access\", \"course\", \"gender\", \"exam_difficulty\"]\n",
    "# cols_to_drop = [\"age\", \"internet_access\"]\n",
    "\n",
    "print(\"\\n--- Applying Feature Cleaning ---\")\n",
    "train_X = train_X0.drop(columns=cols_to_drop, errors='ignore')\n",
    "test_X  = test_X0.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "print(f\"Dropped: {cols_to_drop}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3) One-Hot Encoding\n",
    "# -----------------------------\n",
    "print(\"\\nOne-Hot Encoding...\")\n",
    "all_X = pd.concat([train_X, test_X], axis=0, ignore_index=True)\n",
    "\n",
    "obj_cols = all_X.select_dtypes(include=[\"object\"]).columns\n",
    "all_X[obj_cols] = all_X[obj_cols].astype(str).fillna(\"missing\")\n",
    "all_X = all_X.fillna(0.0)\n",
    "\n",
    "all_X_enc = pd.get_dummies(all_X, columns=obj_cols, drop_first=False)\n",
    "\n",
    "# Split back to Train/Test - No stacking features added here\n",
    "X_train = all_X_enc.iloc[:len(train_X)].values\n",
    "X_test  = all_X_enc.iloc[len(train_X):].values\n",
    "\n",
    "print(f\"Final Input Dimension: {X_train.shape[1]}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) XGBoost CV Training (GPU)\n",
    "# -----------------------------\n",
    "xgb_params = dict(\n",
    "    n_estimators=30000,\n",
    "    learning_rate=0.02,\n",
    "    max_depth=6,\n",
    "    min_child_weight=3.0,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.85,\n",
    "    reg_lambda=2.0,\n",
    "    reg_alpha=0.1,\n",
    "    gamma=0.0,\n",
    "    objective=\"reg:squarederror\",\n",
    "    eval_metric=\"rmse\",\n",
    "    tree_method=\"hist\",           # Required for GPU\n",
    "    device=\"cuda:0\",              # GPU Device\n",
    "    early_stopping_rounds=200,\n",
    "    verbosity=0,\n",
    ")\n",
    "\n",
    "print(\"\\nStarting XGBoost CV Training (No Stacking)...\")\n",
    "N_SPLITS = 5\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "oof_xgb = np.zeros(len(X_train), dtype=float)\n",
    "test_pred_folds = np.zeros((N_SPLITS, len(X_test)), dtype=float)\n",
    "best_iters = []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(kf.split(X_train), 1):\n",
    "    X_tr, y_tr = X_train[tr_idx], y[tr_idx]\n",
    "    X_va, y_va = X_train[va_idx], y[va_idx]\n",
    "\n",
    "    model = XGBRegressor(**xgb_params, random_state=42 + fold)\n",
    "    model.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], verbose=500)\n",
    "\n",
    "    oof_xgb[va_idx] = model.predict(X_va)\n",
    "    test_pred_folds[fold - 1] = model.predict(X_test)\n",
    "\n",
    "    best_iters.append(int(model.best_iteration) + 1)\n",
    "    rmse_fold = float(np.sqrt(mean_squared_error(y_va, oof_xgb[va_idx])))\n",
    "    print(f\"[Fold {fold}] best_iter={best_iters[-1]}  RMSE={rmse_fold:.6f}\")\n",
    "\n",
    "rmse_oof = float(np.sqrt(mean_squared_error(y, oof_xgb)))\n",
    "print(f\"\\nOOF RMSE (Direct XGBoost): {rmse_oof:.6f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Final Fit and Submission\n",
    "# -----------------------------\n",
    "best_n = int(np.mean(best_iters))\n",
    "print(f\"Retraining on full dataset with {best_n} estimators...\")\n",
    "\n",
    "final_params = xgb_params.copy()\n",
    "final_params.pop(\"early_stopping_rounds\", None)\n",
    "final_params[\"n_estimators\"] = best_n\n",
    "final_params[\"verbosity\"] = 1\n",
    "\n",
    "final_model = XGBRegressor(**final_params, random_state=123)\n",
    "final_model.fit(X_train, y, verbose=False)\n",
    "\n",
    "test_pred = final_model.predict(X_test)\n",
    "test_pred = np.clip(test_pred, 0.0, 100.0) # Ensure within score range\n",
    "\n",
    "submission = pd.DataFrame({ID_COL: test_ids, TARGET: test_pred})\n",
    "out_path = f\"{DATA_DIR}/submission_xgb_no_stacking.csv\"\n",
    "submission.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"\\nWrote:\", out_path)\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4239986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and Engineering Features...\n",
      "PHASE 1: Generating Ridge Meta-Features (10-Fold OOF)...\n",
      "  Ridge Fold 1 Complete\n",
      "  Ridge Fold 2 Complete\n",
      "  Ridge Fold 3 Complete\n",
      "  Ridge Fold 4 Complete\n",
      "  Ridge Fold 5 Complete\n",
      "  Ridge Fold 6 Complete\n",
      "  Ridge Fold 7 Complete\n",
      "  Ridge Fold 8 Complete\n",
      "  Ridge Fold 9 Complete\n",
      "  Ridge Fold 10 Complete\n",
      "\n",
      "PHASE 2: Training Regularized XGBoost...\n",
      "[0]\tvalidation_0-rmse:18.84292\n",
      "[1000]\tvalidation_0-rmse:8.76928\n",
      "[2000]\tvalidation_0-rmse:8.72962\n",
      "[3000]\tvalidation_0-rmse:8.70686\n",
      "[4000]\tvalidation_0-rmse:8.69247\n",
      "[5000]\tvalidation_0-rmse:8.68204\n",
      "[6000]\tvalidation_0-rmse:8.67494\n",
      "[7000]\tvalidation_0-rmse:8.66956\n",
      "[8000]\tvalidation_0-rmse:8.66525\n",
      "[9000]\tvalidation_0-rmse:8.66201\n",
      "[10000]\tvalidation_0-rmse:8.65970\n",
      "[11000]\tvalidation_0-rmse:8.65807\n",
      "[12000]\tvalidation_0-rmse:8.65642\n",
      "[13000]\tvalidation_0-rmse:8.65513\n",
      "[14000]\tvalidation_0-rmse:8.65424\n",
      "[15000]\tvalidation_0-rmse:8.65366\n",
      "[15550]\tvalidation_0-rmse:8.65343\n",
      "  Fold 1 RMSE: 8.65342\n",
      "[0]\tvalidation_0-rmse:18.88933\n",
      "[1000]\tvalidation_0-rmse:8.86510\n",
      "[2000]\tvalidation_0-rmse:8.82728\n",
      "[3000]\tvalidation_0-rmse:8.80453\n",
      "[4000]\tvalidation_0-rmse:8.78922\n",
      "[5000]\tvalidation_0-rmse:8.77850\n",
      "[6000]\tvalidation_0-rmse:8.77066\n",
      "[7000]\tvalidation_0-rmse:8.76501\n",
      "[8000]\tvalidation_0-rmse:8.76028\n",
      "[9000]\tvalidation_0-rmse:8.75626\n",
      "[10000]\tvalidation_0-rmse:8.75346\n",
      "[11000]\tvalidation_0-rmse:8.75087\n",
      "[12000]\tvalidation_0-rmse:8.74916\n",
      "[13000]\tvalidation_0-rmse:8.74757\n",
      "[14000]\tvalidation_0-rmse:8.74635\n",
      "[14604]\tvalidation_0-rmse:8.74604\n",
      "  Fold 2 RMSE: 8.74599\n",
      "[0]\tvalidation_0-rmse:18.75065\n",
      "[1000]\tvalidation_0-rmse:8.77081\n",
      "[2000]\tvalidation_0-rmse:8.73308\n",
      "[3000]\tvalidation_0-rmse:8.71036\n",
      "[4000]\tvalidation_0-rmse:8.69540\n",
      "[5000]\tvalidation_0-rmse:8.68580\n",
      "[6000]\tvalidation_0-rmse:8.67869\n",
      "[7000]\tvalidation_0-rmse:8.67339\n",
      "[8000]\tvalidation_0-rmse:8.66946\n",
      "[9000]\tvalidation_0-rmse:8.66653\n",
      "[10000]\tvalidation_0-rmse:8.66447\n",
      "[11000]\tvalidation_0-rmse:8.66243\n",
      "[12000]\tvalidation_0-rmse:8.66121\n",
      "[13000]\tvalidation_0-rmse:8.66028\n",
      "[13887]\tvalidation_0-rmse:8.65970\n",
      "  Fold 3 RMSE: 8.65970\n",
      "[0]\tvalidation_0-rmse:18.81678\n",
      "[1000]\tvalidation_0-rmse:8.78392\n",
      "[2000]\tvalidation_0-rmse:8.74470\n",
      "[3000]\tvalidation_0-rmse:8.72167\n",
      "[4000]\tvalidation_0-rmse:8.70722\n",
      "[5000]\tvalidation_0-rmse:8.69711\n",
      "[6000]\tvalidation_0-rmse:8.68941\n",
      "[7000]\tvalidation_0-rmse:8.68404\n",
      "[8000]\tvalidation_0-rmse:8.67976\n",
      "[9000]\tvalidation_0-rmse:8.67626\n",
      "[10000]\tvalidation_0-rmse:8.67413\n",
      "[11000]\tvalidation_0-rmse:8.67227\n",
      "[12000]\tvalidation_0-rmse:8.67087\n",
      "[13000]\tvalidation_0-rmse:8.66960\n",
      "[14000]\tvalidation_0-rmse:8.66879\n",
      "[15000]\tvalidation_0-rmse:8.66821\n",
      "[15240]\tvalidation_0-rmse:8.66816\n",
      "  Fold 4 RMSE: 8.66813\n",
      "[0]\tvalidation_0-rmse:18.91723\n",
      "[1000]\tvalidation_0-rmse:8.78773\n",
      "[2000]\tvalidation_0-rmse:8.75006\n",
      "[3000]\tvalidation_0-rmse:8.72736\n",
      "[4000]\tvalidation_0-rmse:8.71232\n",
      "[5000]\tvalidation_0-rmse:8.70217\n",
      "[6000]\tvalidation_0-rmse:8.69524\n",
      "[7000]\tvalidation_0-rmse:8.68970\n",
      "[8000]\tvalidation_0-rmse:8.68556\n",
      "[9000]\tvalidation_0-rmse:8.68247\n",
      "[10000]\tvalidation_0-rmse:8.67996\n",
      "[11000]\tvalidation_0-rmse:8.67846\n",
      "[12000]\tvalidation_0-rmse:8.67687\n",
      "[12221]\tvalidation_0-rmse:8.67677\n",
      "  Fold 5 RMSE: 8.67673\n",
      "[0]\tvalidation_0-rmse:18.86822\n",
      "[1000]\tvalidation_0-rmse:8.80571\n",
      "[2000]\tvalidation_0-rmse:8.77027\n",
      "[3000]\tvalidation_0-rmse:8.74765\n",
      "[4000]\tvalidation_0-rmse:8.73344\n",
      "[5000]\tvalidation_0-rmse:8.72393\n",
      "[6000]\tvalidation_0-rmse:8.71683\n",
      "[7000]\tvalidation_0-rmse:8.71174\n",
      "[8000]\tvalidation_0-rmse:8.70727\n",
      "[9000]\tvalidation_0-rmse:8.70389\n",
      "[10000]\tvalidation_0-rmse:8.70094\n",
      "[11000]\tvalidation_0-rmse:8.69903\n",
      "[12000]\tvalidation_0-rmse:8.69765\n",
      "[13000]\tvalidation_0-rmse:8.69642\n",
      "[14000]\tvalidation_0-rmse:8.69554\n",
      "[14914]\tvalidation_0-rmse:8.69526\n",
      "  Fold 6 RMSE: 8.69518\n",
      "[0]\tvalidation_0-rmse:18.86359\n",
      "[1000]\tvalidation_0-rmse:8.79216\n",
      "[2000]\tvalidation_0-rmse:8.75331\n",
      "[3000]\tvalidation_0-rmse:8.73072\n",
      "[4000]\tvalidation_0-rmse:8.71518\n",
      "[5000]\tvalidation_0-rmse:8.70428\n",
      "[6000]\tvalidation_0-rmse:8.69630\n",
      "[7000]\tvalidation_0-rmse:8.69023\n",
      "[8000]\tvalidation_0-rmse:8.68546\n",
      "[9000]\tvalidation_0-rmse:8.68163\n",
      "[10000]\tvalidation_0-rmse:8.67876\n",
      "[11000]\tvalidation_0-rmse:8.67653\n",
      "[12000]\tvalidation_0-rmse:8.67471\n",
      "[13000]\tvalidation_0-rmse:8.67315\n",
      "[14000]\tvalidation_0-rmse:8.67208\n",
      "[14680]\tvalidation_0-rmse:8.67172\n",
      "  Fold 7 RMSE: 8.67168\n",
      "[0]\tvalidation_0-rmse:18.81181\n",
      "[1000]\tvalidation_0-rmse:8.76269\n",
      "[2000]\tvalidation_0-rmse:8.72367\n",
      "[3000]\tvalidation_0-rmse:8.70089\n",
      "[4000]\tvalidation_0-rmse:8.68544\n",
      "[5000]\tvalidation_0-rmse:8.67480\n",
      "[6000]\tvalidation_0-rmse:8.66737\n",
      "[7000]\tvalidation_0-rmse:8.66177\n",
      "[8000]\tvalidation_0-rmse:8.65777\n",
      "[9000]\tvalidation_0-rmse:8.65435\n",
      "[10000]\tvalidation_0-rmse:8.65174\n",
      "[11000]\tvalidation_0-rmse:8.64955\n",
      "[12000]\tvalidation_0-rmse:8.64823\n",
      "[13000]\tvalidation_0-rmse:8.64707\n",
      "[14000]\tvalidation_0-rmse:8.64606\n",
      "[14126]\tvalidation_0-rmse:8.64606\n",
      "  Fold 8 RMSE: 8.64604\n",
      "[0]\tvalidation_0-rmse:18.83808\n",
      "[1000]\tvalidation_0-rmse:8.81660\n",
      "[2000]\tvalidation_0-rmse:8.77883\n",
      "[3000]\tvalidation_0-rmse:8.75522\n",
      "[4000]\tvalidation_0-rmse:8.74018\n",
      "[5000]\tvalidation_0-rmse:8.72958\n",
      "[6000]\tvalidation_0-rmse:8.72144\n",
      "[7000]\tvalidation_0-rmse:8.71578\n",
      "[8000]\tvalidation_0-rmse:8.71113\n",
      "[9000]\tvalidation_0-rmse:8.70741\n",
      "[10000]\tvalidation_0-rmse:8.70465\n",
      "[11000]\tvalidation_0-rmse:8.70269\n",
      "[12000]\tvalidation_0-rmse:8.70087\n",
      "[13000]\tvalidation_0-rmse:8.69957\n",
      "[14000]\tvalidation_0-rmse:8.69856\n",
      "[15000]\tvalidation_0-rmse:8.69777\n",
      "[16000]\tvalidation_0-rmse:8.69723\n",
      "[16927]\tvalidation_0-rmse:8.69699\n",
      "  Fold 9 RMSE: 8.69691\n",
      "[0]\tvalidation_0-rmse:18.83518\n",
      "[1000]\tvalidation_0-rmse:8.78790\n",
      "[2000]\tvalidation_0-rmse:8.75150\n",
      "[3000]\tvalidation_0-rmse:8.72865\n",
      "[4000]\tvalidation_0-rmse:8.71394\n",
      "[5000]\tvalidation_0-rmse:8.70366\n",
      "[6000]\tvalidation_0-rmse:8.69586\n",
      "[7000]\tvalidation_0-rmse:8.69047\n",
      "[8000]\tvalidation_0-rmse:8.68652\n",
      "[9000]\tvalidation_0-rmse:8.68329\n",
      "[10000]\tvalidation_0-rmse:8.68084\n",
      "[11000]\tvalidation_0-rmse:8.67905\n",
      "[12000]\tvalidation_0-rmse:8.67769\n",
      "[13000]\tvalidation_0-rmse:8.67680\n",
      "[13930]\tvalidation_0-rmse:8.67631\n",
      "  Fold 10 RMSE: 8.67623\n",
      "\n",
      "FINAL OOF RMSE: 8.67904\n",
      "Submission saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler, TargetEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # Use GPU 0\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Configuration\n",
    "# -----------------------------\n",
    "DATA_DIR = \"/rds/rds-lxu/ml_datasets/exam_score_predict\" \n",
    "TRAIN_PATH = f\"{DATA_DIR}/train.csv\"\n",
    "TEST_PATH  = f\"{DATA_DIR}/test.csv\"\n",
    "SEED = 1003\n",
    "N_SPLITS = 10 # 10-fold for maximum stability\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Advanced Feature Engineering\n",
    "# -----------------------------\n",
    "def advanced_fe(df):\n",
    "    output = df.copy()\n",
    "    \n",
    "    # Drop IDs\n",
    "    if 'student_id' in output.columns: output.drop('student_id', axis=1, inplace=True)\n",
    "    \n",
    "    # 1. Peer Group Features (Crucial for school data)\n",
    "    output['course_mean_study'] = output.groupby('course')['study_hours'].transform('mean')\n",
    "    output['study_vs_course_avg'] = output['study_hours'] - output['course_mean_study']\n",
    "    \n",
    "    # 2. Polynomials & Logs\n",
    "    output['study_hours_2'] = output['study_hours'] ** 2\n",
    "    output['attendance_2'] = output['class_attendance'] ** 2\n",
    "    output['log_study'] = np.log1p(output['study_hours'])\n",
    "    \n",
    "    # 3. Ratios & Efficiency\n",
    "    epsilon = 1e-5\n",
    "    output['efficiency'] = (output['study_hours'] * output['class_attendance']) / (output['sleep_hours'] + 1)\n",
    "    output['study_per_sleep'] = output['study_hours'] / (output['sleep_hours'] + epsilon)\n",
    "    \n",
    "    # 4. Ordinal Mapping\n",
    "    q_map = {'poor': 0, 'average': 1, 'good': 2}\n",
    "    r_map = {'low': 0, 'medium': 1, 'high': 2}\n",
    "    d_map = {'easy': 0, 'medium': 1, 'hard': 2}\n",
    "    output['sleep_quality_num'] = output['sleep_quality'].map(q_map).fillna(1).astype(int)\n",
    "    output['facility_rating_num'] = output['facility_rating'].map(r_map).fillna(1).astype(int)\n",
    "    output['difficulty_num'] = output['exam_difficulty'].map(d_map).fillna(1).astype(int)\n",
    "    \n",
    "    # 5. Trigonometric (Cyclical)\n",
    "    output['study_sin'] = np.sin(2 * np.pi * output['study_hours'] / 24)\n",
    "    output['study_cos'] = np.cos(2 * np.pi * output['study_hours'] / 24)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Data Preparation\n",
    "# -----------------------------\n",
    "print(\"Loading and Engineering Features...\")\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "TARGET = 'exam_score'\n",
    "\n",
    "train_X_raw = advanced_fe(train_df).drop(columns=['id', TARGET])\n",
    "test_X_raw  = advanced_fe(test_df).drop(columns=['id'])\n",
    "y = train_df[TARGET].values\n",
    "\n",
    "cat_cols = ['gender', 'course', 'internet_access', 'sleep_quality', \n",
    "            'study_method', 'facility_rating', 'exam_difficulty']\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Phase 1: Ridge Stacking\n",
    "# -----------------------------\n",
    "print(\"PHASE 1: Generating Ridge Meta-Features (10-Fold OOF)...\")\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "ridge_oof = np.zeros(len(train_X_raw))\n",
    "ridge_test = np.zeros(len(test_X_raw))\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(kf.split(train_X_raw), 1):\n",
    "    # Ridge needs encoded/scaled data\n",
    "    X_tr_fold, X_va_fold = train_X_raw.iloc[tr_idx], train_X_raw.iloc[va_idx]\n",
    "    y_tr_fold = y[tr_idx]\n",
    "    \n",
    "    # Target Encoding for Linear Model\n",
    "    te = TargetEncoder(target_type='continuous', random_state=SEED)\n",
    "    X_tr_te = te.fit_transform(X_tr_fold[cat_cols], y_tr_fold)\n",
    "    X_va_te = te.transform(X_va_fold[cat_cols])\n",
    "    X_test_te = te.transform(test_X_raw[cat_cols])\n",
    "    \n",
    "    # Combine with numeric\n",
    "    X_tr_lin = np.hstack([X_tr_fold.drop(cat_cols, axis=1).values, X_tr_te])\n",
    "    X_va_lin = np.hstack([X_va_fold.drop(cat_cols, axis=1).values, X_va_te])\n",
    "    X_test_lin = np.hstack([test_X_raw.drop(cat_cols, axis=1).values, X_test_te])\n",
    "    \n",
    "    # Ridge Pipeline\n",
    "    model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('ridge', RidgeCV(alphas=np.logspace(-3, 3, 10)))\n",
    "    ])\n",
    "    \n",
    "    model.fit(X_tr_lin, y_tr_fold)\n",
    "    ridge_oof[va_idx] = model.predict(X_va_lin)\n",
    "    ridge_test += model.predict(X_test_lin) / N_SPLITS\n",
    "    print(f\"  Ridge Fold {fold} Complete\")\n",
    "\n",
    "# Append Ridge prediction to XGBoost features\n",
    "train_X_raw['ridge_pred'] = ridge_oof\n",
    "test_X_raw['ridge_pred'] = ridge_test\n",
    "\n",
    "# Set categoricals for XGBoost\n",
    "for col in cat_cols:\n",
    "    train_X_raw[col] = train_X_raw[col].astype('category')\n",
    "    test_X_raw[col] = test_X_raw[col].astype('category')\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Phase 2: Regularized XGBoost\n",
    "# -----------------------------\n",
    "# L1/L2 Regularization formula:\n",
    "# Loss = MSE + gamma*T + 0.5*lambda*||w||^2 + alpha*||w||\n",
    "xgb_params = {\n",
    "    'n_estimators': 20000,\n",
    "    'learning_rate': 0.005,\n",
    "    'max_depth': 7,             # Depth control\n",
    "    'min_child_weight': 10,     # Prevents nodes from modeling small noise\n",
    "    'subsample': 0.8,           # Row sampling\n",
    "    'colsample_bytree': 0.6,    # Feature sampling\n",
    "    'reg_lambda': 15.0,         # Strong L2 regularization\n",
    "    'reg_alpha': 1.0,           # L1 regularization\n",
    "    'gamma': 0.2,               # Min loss reduction to split\n",
    "    'tree_method': 'hist',\n",
    "    'device': 'cuda',\n",
    "    'enable_categorical': True,\n",
    "    'early_stopping_rounds': 150,\n",
    "    'eval_metric': 'rmse',\n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "print(\"\\nPHASE 2: Training Regularized XGBoost...\")\n",
    "xgb_oof = np.zeros(len(train_X_raw))\n",
    "xgb_test = np.zeros(len(test_X_raw))\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(kf.split(train_X_raw), 1):\n",
    "    X_tr, X_va = train_X_raw.iloc[tr_idx], train_X_raw.iloc[va_idx]\n",
    "    y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "    \n",
    "    model = xgb.XGBRegressor(**xgb_params)\n",
    "    model.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], verbose=1000)\n",
    "    \n",
    "    xgb_oof[va_idx] = model.predict(X_va)\n",
    "    xgb_test += model.predict(test_X_raw) / N_SPLITS\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_va, xgb_oof[va_idx]))\n",
    "    print(f\"  Fold {fold} RMSE: {rmse:.5f}\")\n",
    "\n",
    "print(f\"\\nFINAL OOF RMSE: {np.sqrt(mean_squared_error(y, xgb_oof)):.5f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Submission\n",
    "# -----------------------------\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'exam_score': np.clip(xgb_test, 0, 100)\n",
    "})\n",
    "submission.to_csv(\"submission_final_stack.csv\", index=False)\n",
    "print(\"Submission saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cmbagent_env)",
   "language": "python",
   "name": "cmbagent_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
